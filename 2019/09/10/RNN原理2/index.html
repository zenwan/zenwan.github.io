<!DOCTYPE html>
<html lang="zh-cn">
  <head><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<meta name="description" content="RNN原理2"/><meta name="keywords" content="cv, pytorch, zen" /><link rel="alternate" href="/default" title="zen"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.11.0" />
<link rel="canonical" href="https://zenwan.github.io/2019/09/10/RNN原理2/"/>

<link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css" /><script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
  </script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.11.0" />

<script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>
<script>
  window.config = {"leancloud":{"app_id":null,"app_key":null},"toc":true,"fancybox":true,"pjax":"","latex":true};
</script>

    <title>RNN原理2 - zen</title>
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">zen</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list"><a href="/">
        <li class="mobile-menu-item">首页
          </li>
      </a><a href="/archives/">
        <li class="mobile-menu-item">归档
          </li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">标签
          </li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">分类
          </li>
      </a><a href="/about/">
        <li class="mobile-menu-item">关于
          </li>
      </a></ul>
</nav>
<div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">zen</a>
</div>

<nav class="site-navbar"><ul id="menu" class="menu"><li class="menu-item">
          <a class="menu-item-link" href="/">
            首页
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            归档
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/tags/">
            标签
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/categories/">
            分类
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/about/">
            关于
            </a>
        </li>
      </ul></nav>
</header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content"><article class="post">
    <header class="post-header">
      <h1 class="post-title">RNN原理2
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-09-10
        </span><span class="post-category">
            <a href="/categories/cv/">cv</a>
            </span>
        </div>
    </header>

    <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">文章目录</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#图示"><span class="toc-text">图示</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#传统RNN网络结构"><span class="toc-text">传统RNN网络结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#传统RNN计算过程"><span class="toc-text">传统RNN计算过程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#输入：Input："><span class="toc-text">输入：Input：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#初始隐藏状态-h0"><span class="toc-text">初始隐藏状态(h0)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#输出-Output"><span class="toc-text">输出 Output</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#传统RNN-示例（pytorch"><span class="toc-text">传统RNN 示例（pytorch)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#RNN"><span class="toc-text">RNN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RNN参数列表"><span class="toc-text">RNN参数列表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RNN参数shape"><span class="toc-text">RNN参数shape</span></a></li></ol></li></ol>
    </div>
  </div><div class="post-content"><h2 id="图示"><a href="#图示" class="headerlink" title="图示"></a>图示</h2><p><img src="https://blobscdn.gitbook.com/v0/b/gitbook-28427.appspot.com/o/assets%2F-LoIx0zuH4umMo9bXXA7%2F-LoIylge7IwR9peF-mLO%2F-LoIzonNjtnfJj8KMcaK%2Fimage.png?alt=media&token=ced2ae93-8fc3-4af4-b73c-e3ad12c8d2a6" alt=""></p>
<ul>
<li>黄色矩形框表示 神经网络层</li>
<li>粉色圆圈点向运算</li>
<li>箭头线条 表示向量丛一个点传输到另外一个点</li>
<li>合并线条表示两个向量合并</li>
<li>分叉线条表示向量分发</li>
</ul>
<h2 id="传统RNN网络结构"><a href="#传统RNN网络结构" class="headerlink" title="传统RNN网络结构"></a>传统RNN网络结构</h2><p><img src="https://blobscdn.gitbook.com/v0/b/gitbook-28427.appspot.com/o/assets%2F-LoIx0zuH4umMo9bXXA7%2F-LoIylge7IwR9peF-mLO%2F-LoIyn-GLaLEm7_K_qS4%2Fimage.png?alt=media&token=a16daeb5-e716-449f-9405-4a39761e561f" alt=""></p>
<p>只有1个神经网络层（只有一个黄色矩形 tanh）.<br>{:.info}</p>
<h2 id="传统RNN计算过程"><a href="#传统RNN计算过程" class="headerlink" title="传统RNN计算过程"></a>传统RNN计算过程</h2><h3 id="输入：Input："><a href="#输入：Input：" class="headerlink" title="输入：Input："></a>输入：Input：</h3><blockquote>
<p>tensor containing the features  of the input sequence</p>
</blockquote>
<p>如果batch first 则$X$:<br><strong>input</strong> of shape <code>(batch, seq_len, input_size)</code><br>$$X=[N,L,H_{in}​]$$<br>否则<br><strong>input</strong> of shape <code>(seq_len, batch, input_size)</code><br>$$X=[L,N,H_{in}​]$$</p>
<ul>
<li>L :represents a sequence length</li>
<li>N : batch size</li>
<li>H: input size<br>$$h_t = \text{tanh}(W_{ih} x_t + b_{ih} + W_{hh} h_{(t-1)} + b_{hh})$$</li>
<li>$x_t$ 的shape 为 （<code>batch_size, input_size</code>)</li>
<li>$W_{i,h}$的shape为 （<code>input_size</code>， <code>hidden_size</code>）</li>
<li>$h_{t-1}$的shape为 （<code>batch_size</code>， <code>hidden_size</code>）</li>
<li>$W_{h,h}$的shape为 （<code>hidden_size</code>， <code>hidden_size</code>）</li>
</ul>
<h3 id="初始隐藏状态-h0"><a href="#初始隐藏状态-h0" class="headerlink" title="初始隐藏状态(h0)"></a><strong>初始隐藏状态(h0)</strong></h3><blockquote>
<p>tensor  containing the initial hidden state for each element in the batch.<br> $$h_0=(S, N, H_{out})$$<br><strong>$h_0$</strong> of shape <code>(num_layers * num_directions, batch, hidden_size)</code><br>If the RNN is bidirectional,  num_directions should be 2, else it should be 1.</p>
</blockquote>
<ul>
<li>$H_{out}=\text{hidden_size}$</li>
<li>$N=\text{batch_size}$</li>
<li>$S=\text{num_layers} * \text{num_directions}$</li>
</ul>
<h3 id="输出-Output"><a href="#输出-Output" class="headerlink" title="输出 Output"></a>输出 Output</h3><ul>
<li><p><strong>output1</strong><br>最后一层（last layer）的每个时间单元的隐藏状态</p>
<blockquote>
<p>output of shape <code>(seq_len, batch, num_directions * hidden_size)</code>: tensor<br>containing the output features (<code>h_t</code>) from the last layer of the RNN, for each <code>t</code>.<br>Output1 shape :$(L, N, H_{all})$ where :math:$H_{all}=\text{num_directions} * \text{hidden_size}$</p>
</blockquote>
<p>如果需要输出每个direction 则可以：<br>For the unpacked case, the <strong>directions</strong> can be separated using</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">output.view(seq_len, batch, num_directions, hidden_size)</span><br></pre></td></tr></table></figure>

<ul>
<li>output2:<strong>ht</strong><br>最后一时间单元（<code>t = seq_len</code>）的所有层的隐藏状态。<blockquote>
<p><strong>h_n</strong> of shape <code>(num_layers * num_directions, batch, hidden_size)</code>: tensor<br>containing the hidden state for <code>t = seq_len</code>.<br>Output2: math:<code>(S, N, H_{out})</code> tensor containing the next hidden state<br>for each element in the batch.</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<p>Like <em>output</em>, the ** layers ** can be separated using </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">h_n.view(num_layers, num_directions, batch, hidden_size)</span><br></pre></td></tr></table></figure>
<h2 id="传统RNN-示例（pytorch"><a href="#传统RNN-示例（pytorch" class="headerlink" title="传统RNN 示例（pytorch)"></a>传统RNN 示例（pytorch)</h2><h3 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h3><p>input_size = 10<br>hidden_size = 20<br>num_layers = 2</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rnn = torch.nn.RNN(100, 20, 3)  </span><br><span class="line">input = torch.randn(5, 2, 100)  </span><br><span class="line">h0 = torch.randn(3, 2, 20)  </span><br><span class="line">output, hn = rnn(input, h0)</span><br></pre></td></tr></table></figure>

<h3 id="RNN参数列表"><a href="#RNN参数列表" class="headerlink" title="RNN参数列表"></a>RNN参数列表</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">In  [<span class="number">1</span>]: dict(rnn._parameters).keys()</span><br><span class="line">Out [<span class="number">1</span>]:dict_keys([<span class="string">'weight_ih_l0'</span>, <span class="string">'weight_hh_l0'</span>, <span class="string">'bias_ih_l0'</span>, <span class="string">'bias_hh_l0'</span>, <span class="string">'weight_ih_l1'</span>, <span class="string">'weight_hh_l1'</span>, <span class="string">'bias_ih_l1'</span>, <span class="string">'bias_hh_l1'</span>])</span><br></pre></td></tr></table></figure>
<h3 id="RNN参数shape"><a href="#RNN参数shape" class="headerlink" title="RNN参数shape"></a>RNN参数shape</h3><ul>
<li><p>第1层layer 的$W_{ih}$的shape</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">1</span>]: dict(rnn._parameters).get(<span class="string">'weight_ih_l0'</span>).size()</span><br><span class="line">Out[<span class="number">1</span>]: torch.Size([<span class="number">20</span>, <span class="number">100</span>])</span><br></pre></td></tr></table></figure></li>
<li><p>第2层layer 的$W_{ih}$的shape</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">1</span>]: dict(rnn._parameters).get(<span class="string">'weight_ih_l1'</span>).size()</span><br><span class="line">Out[<span class="number">1</span>]: torch.Size([<span class="number">20</span>, <span class="number">20</span>])</span><br></pre></td></tr></table></figure></li>
<li><p>第三层layer的$W_{ih}$的shape</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">1</span>]: dict(rnn._parameters).get(<span class="string">'weight_ih_l2'</span>).size()</span><br><span class="line">Out[<span class="number">1</span>]: torch.Size([<span class="number">20</span>, <span class="number">20</span>])</span><br></pre></td></tr></table></figure></li>
<li><p>第1-3层layer的$b_{ih}$的shape</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">1</span>]: dict(rnn._parameters).get(<span class="string">'bias_ih_l0'</span>).size()</span><br><span class="line">Out[<span class="number">1</span>]: torch.Size([<span class="number">20</span>])</span><br><span class="line">In [<span class="number">1</span>]: dict(rnn._parameters).get(<span class="string">'bias_ih_l1'</span>).size()</span><br><span class="line">Out[<span class="number">1</span>]: torch.Size([<span class="number">20</span>])</span><br><span class="line">In [<span class="number">1</span>]: dict(rnn._parameters).get(<span class="string">'bias_ih_l2'</span>).size()</span><br><span class="line">Out[<span class="number">1</span>]: torch.Size([<span class="number">20</span>])</span><br></pre></td></tr></table></figure>
</li>
<li><p>output1的shape<br>最后一层，所有时间单元的隐藏状态。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">1</span>]: output.shape</span><br><span class="line">Out[<span class="number">1</span>]: torch.Size([<span class="number">5</span>, <span class="number">2</span>, <span class="number">20</span>])</span><br></pre></td></tr></table></figure>
<p>5：sequence length<br>2:   batch size<br>20:  hidden size</p>
</li>
<li><p>output：ht的shape<br>最后一个时间单元的隐藏状态</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">1</span>]: hn.shape</span><br><span class="line">Out[<span class="number">1</span>]: torch.Size([<span class="number">3</span>, <span class="number">2</span>, <span class="number">20</span>])</span><br></pre></td></tr></table></figure>
<p>3: num_layers<br>2: batch size<br>20: hidden_size</p>
</li>
</ul>
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTI5NzU2Mjg1MiwtNjE5MTMwNjM2LC0yND
U0Njg2MzgsMTc3NDMwMjE0OSwtNDk1MjMxNDgyLDE3MDc2Njk0
NTYsLTMwMTgwOTg3NCwzNTAwNjEyODMsLTE3NzQwMDMxMjEsMT
g1MDczOTA5OSwtMTA4NTMyNzEzNF19
-->

      </div>
      
      <footer class="post-footer">
        <div class="post-tags">
            <a href="/tags/cv/">cv</a>
            <a href="/tags/pytorch/">pytorch</a>
            </div>
        
        <nav class="post-nav"><a class="prev" href="/2019/09/18/LSTM%E4%B8%89%E9%81%93%E9%97%A8/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">LSTM三道门</span>
        <span class="prev-text nav-mobile">上一篇</span>
      </a>
    <a class="next" href="/2019/07/22/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%B8%AD%E5%B8%B8%E8%A7%81%E6%A0%87%E7%AD%BE%E8%AF%B4%E6%98%8E/">
        <span class="next-text nav-default">自然语言处理中常见标签说明@NLP</span>
        <span class="prev-text nav-mobile">下一篇</span>
        <i class="iconfont icon-right"></i>
      </a>
    </nav></footer>
    </article></div><div class="comments" id="comments"></div></div>
      </main>

      <footer id="footer" class="footer"><div class="social-links"><a href="mailto:zenwan021@gmail.com" class="iconfont icon-email" title="email"></a>
        <a href="https://github.com/zenwan" class="iconfont icon-github" title="github"></a>
        <a href="https://www.zhihu.com/people/zenlp" class="iconfont icon-zhihu" title="zhihu"></a>
        <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    </div><div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://hexo.io/">Hexo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">&copy;2015 - 2019<span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">nanking</span>
  </span>
</div>
</footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div><script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  <script type="text/javascript" src="/js/src/even.js?v=2.11.0"></script>
</body>
</html>
