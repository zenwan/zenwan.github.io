<!DOCTYPE html>
<html lang="zh-cn">
  <head><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<meta name="description" content="BatchNormal@CV"/><meta name="keywords" content="cv, pytorch, zen" /><link rel="alternate" href="/default" title="zen"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.11.0" />
<link rel="canonical" href="https://zenwan.github.io/2019/06/05/BatchNormal/"/>

<link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css" /><script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
  </script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.11.0" />

<script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>
<script>
  window.config = {"leancloud":{"app_id":null,"app_key":null},"toc":true,"fancybox":true,"pjax":"","latex":true};
</script>

    <title>BatchNormal@CV - zen</title>
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">zen</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list"><a href="/">
        <li class="mobile-menu-item">首页
          </li>
      </a><a href="/archives/">
        <li class="mobile-menu-item">归档
          </li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">标签
          </li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">分类
          </li>
      </a><a href="/about/">
        <li class="mobile-menu-item">关于
          </li>
      </a></ul>
</nav>
<div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">zen</a>
</div>

<nav class="site-navbar"><ul id="menu" class="menu"><li class="menu-item">
          <a class="menu-item-link" href="/">
            首页
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            归档
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/tags/">
            标签
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/categories/">
            分类
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/about/">
            关于
            </a>
        </li>
      </ul></nav>
</header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content"><article class="post">
    <header class="post-header">
      <h1 class="post-title">BatchNormal@CV
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-06-05
        </span><span class="post-category">
            <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
            </span>
        </div>
    </header>

    <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">文章目录</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#BatchNorm"><span class="toc-text">BatchNorm</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#为什么使用BatchNorm"><span class="toc-text">为什么使用BatchNorm?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#常见BN"><span class="toc-text">常见BN</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#全连接BN示例"><span class="toc-text">全连接BN示例</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#对全连接层做批量归一化"><span class="toc-text">对全连接层做批量归一化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#对卷积层做批量归一化"><span class="toc-text">对卷积层做批量归一化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pytorch-示例"><span class="toc-text">Pytorch 示例</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#BatchNorm1d"><span class="toc-text">BatchNorm1d</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#BatchNorm2d"><span class="toc-text">BatchNorm2d</span></a></li></ol></li></ol>
    </div>
  </div><div class="post-content"><h2 id="BatchNorm"><a href="#BatchNorm" class="headerlink" title="BatchNorm"></a>BatchNorm</h2><p>批量归一化（batch normalization）层，它能让较深的神经网络的训练变得更加容易，</p>
<h2 id="为什么使用BatchNorm"><a href="#为什么使用BatchNorm" class="headerlink" title="为什么使用BatchNorm?"></a>为什么使用BatchNorm?</h2><ul>
<li>数据归一化到一定范围（特征缩放-Feature scaling），避免梯度离散，加速收敛。</li>
</ul>
<p><img src="http://static.zybuluo.com/zenzenzen/t9ama91b0xkh2pbeq4fwv1f8/image_1dcjcutsjo5r1mhh120nhima6j9.png" alt="image_1dcjcutsjo5r1mhh120nhima6j9.png-191.6kB"><br><img src="http://static.zybuluo.com/zenzenzen/x0rm5ye3yy41zbt9gm4vooju/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20190605164641.png" alt="微信截图_20190605164641.png-573.4kB"><br>BatchNorm 通常应用在全连接层或者卷积层之后，激活函数之前。如下图所示：<br><img src="http://static.zybuluo.com/zenzenzen/y965me0zedc2wkg4al7d9vuq/image_1dcjegs721c75af6mvcmat1r9vr.png" alt="image_1dcjegs721c75af6mvcmat1r9vr.png-29.9kB"></p>
<h2 id="常见BN"><a href="#常见BN" class="headerlink" title="常见BN"></a>常见BN</h2><p> <img src="http://static.zybuluo.com/zenzenzen/b9a95mcz2m1aa9on34gsaku6/1_ETvcPhYH1lCfXndMiKW-jQ.png" alt="1_ETvcPhYH1lCfXndMiKW-jQ.png-331.7kB"><br> 如上图BatchNorm所示:<br> 有N张图片，C个通道，图像大小为$[H,W]$，把图片的维度拍平成$[H \times W]$，<br> 可以得到[N,C,H \times W]的数据格式，取所有图片，分别在每个通道上进行归一化处理，则可以得到$C$（和输入的<strong>通道数</strong>一致）个归一化结果（均值和方差）。</p>
<p>  如上图LayerNorm所示:<br>  取所有每张图片的所有通道数，分别在每张图片上进行归一化处理，则可以得到$N$（和输入的batch大小一致）个归一化结果（均值和方差）。</p>
<p> 如上图InstanceNorm所示:<br>  取所有每张图片的每个通道，分别在每张图片每个通道上进行归一化处理，则可以得到$[N,C]$（和输入的batch大小、通道数相关）个归一化结果（均值和方差）。</p>
<h2 id="全连接BN示例"><a href="#全连接BN示例" class="headerlink" title="全连接BN示例"></a>全连接BN示例</h2><h3 id="对全连接层做批量归一化"><a href="#对全连接层做批量归一化" class="headerlink" title="对全连接层做批量归一化"></a>对全连接层做批量归一化</h3><p><img src="http://static.zybuluo.com/zenzenzen/yheuvar7695ipjddn4uo2oc4/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20190605170809.png" alt="微信截图_20190605170809.png-431.2kB"><br>我们先考虑如何对全连接层做批量归一化。通常，我们将批量归一化层置于全连接层中的仿射变换和激活函数之间。设全连接层的输入为$\boldsymbol{u}$，权重参数和偏差参数分别为$\boldsymbol{W}$和$\boldsymbol{b}$，激活函数为$\phi$。设批量归一化的运算符为$\text{BN}$。那么，使用批量归一化的全连接层的输出为</p>
<p>$$\phi(\text{BN}(\boldsymbol{x})),$$<br>其中批量归一化输入$\boldsymbol{x}$由仿射变换</p>
<p>$$\boldsymbol{x} = \boldsymbol{W\boldsymbol{u} + \boldsymbol{b}}$$</p>
<p>得到。考虑一个由$m$个样本组成的小批量，仿射变换的输出为一个新的小批量$\mathcal{B} = {\boldsymbol{x}^{(1)}$, $\ldots, \boldsymbol{x}^{(m)} }$。它们正是批量归一化层的输入。对于小批量$\mathcal{B}$中任意样本$\boldsymbol{x}^{(i)} \in \mathbb{R}^d, 1 \leq i \leq m$，批量归一化层的输出同样是$d$维向量</p>
<p>$$\boldsymbol{y}^{(i)} = \text{BN}(\boldsymbol{x}^{(i)}),$$</p>
<p>并由以下几步求得。首先，对小批量$\mathcal{B}$求<strong>均值</strong>和<strong>方差</strong>：</p>
<p>$$\boldsymbol{\mu}<em>\mathcal{B} \leftarrow \frac{1}{m}\sum</em>{i = 1}^{m} \boldsymbol{x}^{(i)}$$,</p>
<p>$$\boldsymbol{\sigma}<em>\mathcal{B}^2 \leftarrow \frac{1}{m} \sum</em>{i=1}^{m}(\boldsymbol{x}^{(i)} - \boldsymbol{\mu}_\mathcal{B})^2,$$<br>其中的平方计算是按元素求平方。接下来，使用按元素开方和按元素除法对$\boldsymbol{x}^{(i)}$标准化：</p>
<p>$$\hat{\boldsymbol{x}}^{(i)} \leftarrow \frac{\boldsymbol{x}^{(i)} - \boldsymbol{\mu}_\mathcal{B}}{\sqrt{\boldsymbol{\sigma}_\mathcal{B}^2 + \epsilon}}$$,<br>这里$\epsilon &gt; 0$是一个很小的常数，保证分母大于0。在上面标准化的基础上，批量归一化层引入了两个可以学习的模型参数，拉伸（scale）参数 $\boldsymbol{\gamma} $和偏移（shift）参数 $\boldsymbol{\beta}$。这两个参数和$\boldsymbol{x}^{(i)}$形状相同，皆为$d$维向量。它们与$\boldsymbol{x}^{(i)}$分别做按元素乘法（符号$\odot$）和加法计算：</p>
<p>$${\boldsymbol{y}}^{(i)} \leftarrow \boldsymbol{\gamma} \odot \hat{\boldsymbol{x}}^{(i)} + \boldsymbol{\beta}.$$</p>
<p>至此，我们得到了$\boldsymbol{x}^{(i)}$的批量归一化的输出$\boldsymbol{y}^{(i)}$。 值得注意的是，可学习的拉伸和偏移参数保留了不对$\hat{\boldsymbol{x}}^{(i)}$做批量归一化的可能：此时只需学出$\boldsymbol{\gamma} = \sqrt{\boldsymbol{\sigma}_\mathcal{B}^2 + \epsilon}$和$\boldsymbol{\beta} = \boldsymbol{\mu}_\mathcal{B}$。我们可以对此这样理解：如果批量归一化无益，理论上，学出的模型可以不使用批量归一化。<br>BN具体算法过程<br><img src="http://static.zybuluo.com/zenzenzen/5ub2vwuxndz8niztqrq9dxau/image_1dcjekipv1utfitf193fn7ii9p18.png" alt="image_1dcjekipv1utfitf193fn7ii9p18.png-76.3kB"><br>如上图所示，BN步骤主要分为4步：</p>
<ul>
<li>求每一个训练批次数据的均值</li>
<li>使用求得的均值和方差对该批次的训练数据做归一化，获得0-1分布。其中ε是为了避免除数为0时所使用的微小正数。</li>
<li>尺度变换和偏移：将xi乘以γ调整数值大小，再加上β增加偏移后得到yi，这里的γ是尺度因子，β是平移因子。这一步是BN的精髓，由于归一化后的xi基本会被限制在正态分布下，使得网络的表达能力下降。为解决该问题，我们引入两个新的参数：γ,β。 γ和β是在训练时网络自己学习得到的。</li>
</ul>
<h3 id="对卷积层做批量归一化"><a href="#对卷积层做批量归一化" class="headerlink" title="对卷积层做批量归一化"></a>对卷积层做批量归一化</h3><p>对卷积层来说<strong>，批量归一化发生在卷积计算之后、应用激活函数之前</strong>。如果卷积计算输出多个通道，我们需要<strong>对这些通道的输出分别做批量归一化</strong>，且<strong>每个通道都拥有独立的拉伸和偏移参数</strong>，并均为标量。设小批量中有$m$个样本。在单个通道上，假设卷积计算输出的高和宽分别为$p$和$q$。我们需要对该通道中$m \times p \times q$个元素同时做批量归一化。对这些元素做标准化计算时，我们使用相同的均值和方差，即该通道中$m \times p \times q$个元素的均值和方差。</p>
<h2 id="Pytorch-示例"><a href="#Pytorch-示例" class="headerlink" title="Pytorch 示例"></a>Pytorch 示例</h2><h3 id="BatchNorm1d"><a href="#BatchNorm1d" class="headerlink" title="BatchNorm1d"></a>BatchNorm1d</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">batchInput = torch.randn(<span class="number">4</span>,<span class="number">3</span>,<span class="number">784</span>)</span><br><span class="line">layer = torch.nn.BatchNorm1d(num_features=<span class="number">3</span>,affine=<span class="literal">True</span>) <span class="comment">#通道数</span></span><br><span class="line">out = layer(batchInput)</span><br><span class="line">print(batchInput.shape)</span><br><span class="line">print(layer.running_mean)</span><br><span class="line">print(layer.running_var)</span><br></pre></td></tr></table></figure>
<p>输出</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([<span class="number">4</span>, <span class="number">3</span>, <span class="number">784</span>])</span><br><span class="line">tensor([<span class="number">0.0018</span>, <span class="number">0.0010</span>, <span class="number">0.0023</span>])</span><br><span class="line">tensor([<span class="number">1.0001</span>, <span class="number">0.9956</span>, <span class="number">0.9979</span>])</span><br></pre></td></tr></table></figure>
<h3 id="BatchNorm2d"><a href="#BatchNorm2d" class="headerlink" title="BatchNorm2d"></a>BatchNorm2d</h3><p>输入为4张3通道的彩色RGB图像，图像尺寸为28×28</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">batchInput2 = torch.randn(<span class="number">4</span>,<span class="number">3</span>,<span class="number">28</span>,<span class="number">28</span>)</span><br><span class="line">layer2 = torch.nn.BatchNorm2d(num_features=<span class="number">3</span>,affine=<span class="literal">True</span>) <span class="comment">#通道数</span></span><br><span class="line">out2 = layer2(batchInput2)</span><br><span class="line">print(layer2.running_mean)</span><br><span class="line">print(layer2.running_var)</span><br><span class="line">print(vars(layer2))</span><br></pre></td></tr></table></figure>
<p>权重参数和偏差参数分别为$\boldsymbol{W}$和$\boldsymbol{b}$：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(layer2.weight)</span><br><span class="line">print(layer2.bias)</span><br></pre></td></tr></table></figure>
<p>output:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([0.6736, 0.3242, 0.7500], requires_grad=True)</span><br><span class="line">tensor([0., 0., 0.], requires_grad=True)</span><br></pre></td></tr></table></figure>
<p>再看下归一化后的数据分布：全局均值与方差</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(layer2.running_mean)</span><br><span class="line">print(layer2.running_var)</span><br></pre></td></tr></table></figure>
<p>output:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([-0.0009,  0.0008, -0.0017])</span><br><span class="line">tensor([1.0034, 1.0035, 0.9970])</span><br></pre></td></tr></table></figure>
<p>可以看出数据已经符合均值为0，方差为1的分布。</p>
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTk3ODg5NjEzMV19
-->
      </div>
      
      <footer class="post-footer">
        <div class="post-tags">
            <a href="/tags/cv/">cv</a>
            <a href="/tags/pytorch/">pytorch</a>
            </div>
        
        <nav class="post-nav"><a class="prev" href="/2019/07/09/ResNet/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">ResNet@CV</span>
        <span class="prev-text nav-mobile">上一篇</span>
      </a>
    <a class="next" href="/2019/06/04/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C@CV/">
        <span class="next-text nav-default">卷积神经网络如何工作@CV</span>
        <span class="prev-text nav-mobile">下一篇</span>
        <i class="iconfont icon-right"></i>
      </a>
    </nav></footer>
    </article></div><div class="comments" id="comments"></div></div>
      </main>

      <footer id="footer" class="footer"><div class="social-links"><a href="mailto:zenwan021@gmail.com" class="iconfont icon-email" title="email"></a>
        <a href="https://github.com/zenwan" class="iconfont icon-github" title="github"></a>
        <a href="https://www.zhihu.com/people/zenlp" class="iconfont icon-zhihu" title="zhihu"></a>
        <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    </div><div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://hexo.io/">Hexo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">&copy;2015 - 2019<span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">nanking</span>
  </span>
</div>
</footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div><script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  <script type="text/javascript" src="/js/src/even.js?v=2.11.0"></script>
</body>
</html>
